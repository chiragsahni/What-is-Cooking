{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score #how good model is \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import sklearn.ensemble as skens\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#visualization imports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Put data in the correct format in order to run RandomForestClassifier later in the code: \n",
    "\n",
    "- load in train.json data from kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('/kaggle/input/whats-cooking/train.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json('/kaggle/input/whats-cooking/test.json')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "The dataset in both train and test is in a format that cannot be used in a Random Forest Classifier. For the train data, the columns need to be every unique ingredient with a 0 or 1 if the ingredient is in a particular cuisine. In the next part, re-load both the test data and train data, and create a dictionary that will be used to create a DataFrame with the information formatted correctly. Do the same thing for the test data as well. \n",
    "\n",
    "The test.json data does not have cuisines listed. We are going to use the random forest classifier that is going to be created below on the train.json data. Since the test.json does not have cusines listed, I am going to run cross validation on this data to get an accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Re-read in json files to be cleaned before putting it into pandas DataFrames. \n",
    "- read in test.json and assign it to the variable test_data \n",
    "- read in train.json and assign it to the variable data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/kaggle/input/whats-cooking/train.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "with open('/kaggle/input/whats-cooking/test.json') as json_file:\n",
    "    test_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Get a list of all the unique ingredients in both data (train data) and test_data (test data) and assign the resulting lists to two separate variables.  The train data ingredients, which comes from the values in the variable data, will be a assigned to a list called unique_ingredients. The test data ingredients, which comes from the values in the variable test_data, will be assigned to a list called unique_ingredients_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data \n",
    "lst = []\n",
    "for x in data: \n",
    "    id_=x[\"id\"]\n",
    "    ingredients = x['ingredients']\n",
    "    for ingred in ingredients:\n",
    "        lst.append(ingred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data ingredients \n",
    "unique_ingredients=list(set(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "lst2 = []\n",
    "for x in test_data: \n",
    "    id_=x[\"id\"]\n",
    "    ingredients = x['ingredients']\n",
    "    for ingred in ingredients:\n",
    "        lst2.append(ingred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data ingredients \n",
    "unique_ingredients_test =list(set(lst2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Create a dictionary called ingred_value that formats the train data correctly, called data, to be used for a Random Forest Classifier. This dictionary will be used to create a DataFrame called train_df.\n",
    "\n",
    "This is a dictionary called ingred_value where one of the keys is called 'cusine' and the value is a list of all the cuisines in the dataset. The other keys in the dictionary is all the ingredients in the dataset as keys. The values are 0 or 1 depending on if the particular cuisine mentioned has the ingredient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingred_value = {ingredient: [] for ingredient in unique_ingredients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "ciusine = [] \n",
    "ingredient_lst = unique_ingredients\n",
    "ingredients_for_id =[] \n",
    "for x in data: \n",
    "    id_=x[\"id\"]\n",
    "    ingredients_in_id = x['ingredients']\n",
    "    ids.append(id_)\n",
    "    ciusine.append(x[\"cuisine\"])\n",
    "    for ingred in ingred_value: \n",
    "            if ingred in ingredients_in_id:\n",
    "                ingred_value[ingred].append(1)\n",
    "            else: \n",
    "                 ingred_value[ingred].append(0)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key in the ingred_value dictionary called cuisine \n",
    "# The value is now a list of cuisines in the dataset \n",
    "# the list called ciusine was created above \n",
    "\n",
    "ingred_value[\"cuisine\"] = ciusine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Created a DataFrame called train_df with the ingred_value dictionary that was created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(ingred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation: \n",
    "The DataFrame train_df is now formatted correctly to perform machine learning classifiers on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Repeat steps b and c above for test_data. Create a dictionary called ingred_value_test that formats the test data correctly, called test_data, to be used for a Random Forest Classifier. This dictionary will be used to create a DataFrame called test_df.\n",
    "\n",
    "This is a dictionary called ingred_value_test where the keys in the dictionary is all the ingredients in the dataset as keys. The values are 0 or 1 depending on if the particular id mentioned has the ingredient. \n",
    "\n",
    "NOTE: as talked about above, the test dataset does not have any cuisines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingred_value_test = {ingredient: [] for ingredient in unique_ingredients_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for test data: \n",
    "ids = []\n",
    "ingredient_lst = unique_ingredients_test\n",
    "ingredients_for_id =[] \n",
    "for x in test_data: \n",
    "    id_=x[\"id\"]\n",
    "    ingredients_in_id = x['ingredients']\n",
    "    ids.append(id_)\n",
    "    for ingred in ingred_value_test: \n",
    "            if ingred in ingredients_in_id:\n",
    "                ingred_value_test[ingred].append(1)\n",
    "            else: \n",
    "                 ingred_value_test[ingred].append(0)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a key in the ingred_value_test dictionary called id\n",
    "# The value is now a list of ids in the dataset \n",
    "# the list called ids was created above \n",
    "\n",
    "ingred_value_test[\"id\"] = ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Created a DataFrame called test_df with the ingred_value_test dictionary that was created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(ingred_value_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Split train data DataFrame, called train_df, into variables X and y. X is all the variables, in this case ingredients, that will be used to predict the type of cuisine. The variable y is the categorical variable cuisine. \n",
    "- X is the features, in this case ingredients, that will be used to try and figure out the classification. \n",
    "- The values of variable y is what we are trying to predict in this challenge: the type of cuisine given ingredients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df[\"cuisine\"]\n",
    "X = train_df.drop(\"cuisine\", axis = 1) #all variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Assign all the ingredients from the test data DataFrame, called test_df, to the variable X_test. X_test is all the variables, in this case ingredients, that will be used to predict the type of cuisine. I am going to drop \"id\". \n",
    "- X_test is the features, in this case ingredients, that will be used to try and figure out the classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(\"id\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Create a Random Forest Classifier using the package called sklearn on the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = skens.RandomForestClassifier(n_estimators=10,oob_score=True, criterion='entropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Using the Random Forest Classifier created, called rf_model, fit the data using the train data: X and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)Perform cross validation using the Random Forest Classifier object, called rf_model, and the train data, called X and y, to get an accuracy score for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf_model, X,y, cv=5) #do this 5 times and withhold info each tim \n",
    "#score is the average score for each of the cross validaiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an accuracy score using the mean and standard deviation multiplied by 2\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Get predicted labels for the test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Filter X_train and X_test to only have columns that are represented in both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[~X.isin(X_test.columns())]\n",
    "columns_in_train = set(X.columns)\n",
    "columns_in_test = set(X_test.columns)\n",
    "columns_in_both = list(columns_in_train & columns_in_test)\n",
    "new_df_with_columns_in_both_train = X[columns_in_both]\n",
    "new_df_with_columns_in_both_test = X_test[columns_in_both]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Create a random forest classifier object, and then fit the model with new_df_with_columns_in_both_train and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_for_test = skens.RandomForestClassifier(n_estimators=10,\n",
    "                                                oob_score=True, \n",
    "                                                criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_for_test.fit(new_df_with_columns_in_both_train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Get predicted labels for new_df_with_columns_in_both_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_for_test = rf_model_for_test.predict(new_df_with_columns_in_both_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Create a copy of the test_df and assign it to the variable test_df_predicted. Add a column to test_df_predicted with the predicted labels, called predicted_y_for_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_predicted = test_df.copy()\n",
    "\n",
    "test_df_predicted[\"predicted_labels\"] = predicted_y_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Perform cross validation using the Random Forest Classifier object, called rf_model_for_test, and the train data, called new_df_with_columns_in_both_train and y, to get an accuracy score for this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_of_new_model = cross_val_score(rf_model_for_test, new_df_with_columns_in_both_train,y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_of_new_model.mean(), scores_of_new_model.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
